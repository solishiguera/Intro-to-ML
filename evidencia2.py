# -*- coding: utf-8 -*-
"""Evidencia2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KGHY-cScuA5VocaQ21wBnHeiG7pbAQvL
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from pandas.plotting import scatter_matrix
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn import *

"""# Descripción de datos
* Name: Name of cereal
* mfr: Manufacturer of cereal
  * A = American Home Food Products;
  * G = General Mills
  * K = Kelloggs
  * N = Nabisco
  * P = Post
  * Q = Quaker Oats
  * R = Ralston Purina
* type:
  * cold
  * hot
* calories: calories per serving
* protein: grams of protein
* fat: grams of fat
* sodium: milligrams of sodium
* fiber: grams of dietary fiber
* carbo: grams of complex carbohydrates
* sugars: grams of sugars
* potass: milligrams of potassium
* vitamins: vitamins and minerals - 0, 25, or 100, indicating the typical percentage of FDA recommended
* shelf: display shelf (1, 2, or 3, counting from the floor)
* weight: weight in ounces of one serving
* cups: number of cups in one serving
* rating: a rating of the cereals (Possibly from Consumer Reports?)
"""

df = pd.read_csv('cereal.csv',  engine='python')
"""
df.head()

df.shape

df.isna().sum()

df.describe()
"""

corr_df = df.corr(method='pearson')

"""
plt.figure(figsize=(12, 9))
sns.heatmap(corr_df, annot=True, cmap="Blues")
plt.show()
"""

# x = df[['protein', 'fat', 'sodium', 'fiber', 'carbo', 'sugars', 'potass', 'vitamins']]
# x = df[['fat', 'sodium', 'sugars', 'weight']]
x = df[['calories','protein', 'fat', 'sodium', 'fiber', 'carbo', 'sugars', 'potass', 'vitamins', 'shelf', 'weight', 'cups']]
# Nuestra varible dependiente
y = df[['rating']]

# Separamos un conjunto de datos para entrenar y otro para probar
X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=4)

#Nivel de significancia
alpha = 0.05

# Inicialización de modelos
ridge_mod = Ridge(alpha)
lasso_mod = Lasso(alpha)
forest_reg = RandomForestRegressor()
ml_mod = LinearRegression()

# Training model
ml_mod.fit(X_train,y_train)

# Training predictions
y_train_pred_ml = ml_mod.predict(X_train)

# Model evaluation
r1_ml = metrics.r2_score(y_train, y_train_pred_ml)
print('\n || ~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~ || \n')
print("Score de datos de entrenamiento: " +"{:.6}".format(r1_ml*100)+"%")

# Testing predictions
y_test_pred_ml = ml_mod.predict(X_test)

# Model evaluation
r2_ml = metrics.r2_score(y_test, y_test_pred_ml)
print("Score de datos de prueba: " +"{:.6}".format(r2_ml*100)+"%")

mse_ml = mean_squared_error(y_test,y_test_pred_ml)
print("Error cuadrático medio: " +"{:.6}".format(np.sqrt(mse_ml)))

# Predicción completa de los datos
predict_rating = ml_mod.predict(x).tolist()

# Tabla con valores reales y de prediccion
comparison = pd.DataFrame({'Real': df["rating"], 'Predicción': predict_rating})
muestra = comparison.head(25) # Elegimos 25 valores de muestra
print('\n || ~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~ || \n')
print("Predicciones de 15 datos: \n")
print(muestra.head(15))
print('\n || ~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~ || \n')